### 키-값 저장소 설계
* 키-값 저장소는 키-값 데이터베이스라고도 불리는 비 관계형 데이터베이스이다.
* 키-값 쌍에서의 값은 문자열일 수도 있고 리스트일 수도 있고 객체일 수도 있다.
* 아마존 다이나모, memcached, Redis와 같은 것들이 있다.

**문제 이해 및 설계 범위 확정**
* 다음 특성을 갖는 키-값 저장소 설계
  * 키-값 쌍의 크기는 10KB 이하이다.
  * 큰 데이터를 저장할 수 있어야 한다.
  * 높은 가용성을 제공해야 한다. 따라서 시스템은 설사 장애가 있더라도 빨리 응답해야 한다.
  * 높은 규모 확장성을 제공해야 한다. 따라서 트래픽 양에 따라 자동적으로 서버 증설/삭제가 이루어져야 한다.
  * 데이터 일관성 수즌은 조정이 가능해야 한다.
  * 응답 지연시간이 짧아야 한다.

**단일 서버 키-값 저장소**
* 한대 서버만 사용하는 키-값 저장소를 설계하는 것은 쉽다.
* 가장 직관적인 방법은 키-값 쌍 전부를 메모리에 해시 테이블로 저장하는 것이다.
* 그러나 이 접근법은 빠른 속도를 보장하긴 하지만 모든 데이터를 메모리 안에 두는 것이 불가능할 수도 있다는 약점을 가지고 있다.
  * 개선책으로는 다음과 같다.
    * 데이터 압축
    * 자주 쓰이는 데이터만 메모리에 두고 나머지는 디스크에 저장
* 이렇게 개선하더라도 한 대 서버로는 부족한 때가 곧 찾아온다. 많은 데이터를 저장하려면 분산 키-값 저장소를 만들 필요가 있다.

**분산 키-값 저장소**
* 분산 해시 테이블이라고도 불린다.
* 분산 시스템을 설계할 때는 CAP(Consistency, Availability, Partition Tolerance theorem)를 이해하고 있어야한다.

**CAP**
* 일관성, 가용성, 파티션 감내라는 세가지 요구 사항을 동시에 만족하는 분산 시스템을 설계하는 것은 불가능하다는 정리다.
* 데이터 일관성: 분산 시스템에 접속하는 모든 클라이언트는 언제나 같은 데이터를 보게 되어야 한다.
* 가용성: 일부 노드에 장애가 발생해도 항상 응답 받을 수 있어야 한다.
* 파티션 감내: 파티션은 두 노드 사이에 통신 장애가 의미한다. 파티션 감내는 네트워크에 파티션이 생기더라도 시스템은 계속 동작해야 한다는 뜻이다.
* CAP 정리는 이들 가운데 어떤 두 가지를 충족하려면 나머지 하나는 반드시 희생되어야 한다는 것을 의미한다.
* CP 시스템: 일관성과 파티션 감내를 지원, 가용성을 희생
* AP 시스템: 가용성과 파티션 감내를 지원, 데이터 일관성 희생
* CA 시스템: 일관성과 가용성을 지원, 파티션 감내 희생하지만 통상 네트워크 장애는 피할 수 없는 일이므로 실세계에 CA 시스템은 존재하지 않는다.

**이상적 상태**
* 이상적 환경이라면 네트워크가 파티션되는 상황은 절대로 일어나지 않을 것이다.
* n1, n2, n3의 키-값 저장소가 있다면 n1에 기록된 데이터는 나머지에 모두 복제되어 데이터 일관성과 가용성도 만족된다.

**실세계의 분산 시스템**
* 분산 시스템은 파티션 문제를 피할 수 없다. 그리고 파티션 문제가 발생하면 우리는 일관성과 가용성 사이에서 하나를 선택해야 한다.
* n3에 장애가 발생해 n1, n2와 통신할 수 없는 상황에서 n1, n2에 기록한 데이터는 n3에 전달되지 않고 그 반대도 마찬가지다.
* 가용성 대신 일관성을 선택한다면(CP 시스템) 세 서버 사이에 생길 수 있는 데이터 불일치 문제를 피하기 위해 n1, n2에 대해 쓰기 연산을 중단시켜야 한다.
  * 은행권 시스템은 온라인 뱅킹 시스템이 계좌 최신 정보를 출력하지 못하면 큰 문제이기 때문에 보통 데이터 일관성을 양보하지 않는다.
* 일관성 대신 가용성을 선택한 시스템(AP 시스템)은 설사 낡은 데이터를 반환할 위험이 있더라도 계속 읽기 연산을 허용해야 한다.
  * 아울러 n1, n2는 계속 쓰기 연산을 허용할 것이고, 파티션 문제가 해결된 뒤에 새 데이터를 n3에 전송할 것이다.

**데이터 파티션**
* 대규모 애플리케이션의 경우 전체 데이터를 한 대 서버에 욱여넣는 것은 불가능하다.
* 가장 단순한 해결책은 데이터를 작은 파티션들로 분할한 다음 여러 대 서버에 저장하는 것이다.
* 데이터를 파티션 단위로 나눌 때는 다음 두 가지 문제를 중요하게 따져봐야 한다.
  * 데이터를 여러 서버에 고르게 분산할 수 있는가
  * 노드가 추가되거나 삭제될 때 데이터의 이동을 최소화할 수 있는가
* 안정 해시는 위와 같은 문제를 푸는 데 적합한 기술이다.
  * 규모 확장 자동화: 시스템 부하에 따라 서버가 자동으로 추가되거나 삭제되도록 만들 수 있다.
  * 다양성: 각 서버의 용량에 맞게 가상 노드의 수를 조정할 수 있다. 다시 말해, 고성능 서버는 더 많은 가상 노드를 갖도록 설정할 수 있다.

**데이터 다중화**
* 높은 가용성과 안정성을 확보하기 위해서는 데이터를 N개 서버에 비동기적으로 다중화할 필요가 있다.
* 어떤 키를 해시 링 위에 배치한 후, 그 지점으로부터 시계 방향으로 링을 순회하면서 만나는 첫 N개 서버에 데이터 사본을 보관시킨다.
* 가상 노드를 사용한다면 N개의 노드가 대응될 실제 물리서버의 개수가 N보다 작아질 수 있기 때문에 같은 물리 서버를 중복 선택하지 않도록 해야 한다.
* 같은 데이터 센터에 속한 노드는 정전, 네트워크 이슈, 자연재해 등의 문제를 동시에 겪을 가능성이 있기 때문에 데이터의 사본은 다른 센터의 서버에 보관하고, 센터들은 고속 네트워크로 연결한다.

**데이터 일관성**
* 여러 노드에 다중화된 데이터는 적절히 동기화가 되어야 한다.
* 정족수 합의 프로토콜을 사용하면 읽기/쓰기 연산 모두에 일관성을 보장할 수 있다.
* 관계 정의
  * N = 사본 개수
  * W = 쓰기 연산에 대한 정족수. 쓰기 연산이 성공한 것으로 간주되려면 적어도 W개의 서버로부터 쓰기 연산이 성공했다는 응답을 받아야 한다.
  * R = 읽기 연산에 대한 정족수. 읽기 연산이 성공한 것으로 간주되려면 적어도 R개의 서버로부터 응답을 받아야 한다.
* W = 1은 데이터가 한 대 서버에만 기록된다는 뜻이 아니다. 쓰기 연산이 성공했다고 판단하기 위해 중재자는 최소 한 대 서버로부터 쓰기 응답을 받아야 한다는 뜻이다.
* W, R, N의 값을 정하는 것은 응답 지연과 데이터 일관성 사이의 타협점을 찾는 전형적인 과정이다.
  * W = 1, R = 1인 구성의 경우 중재자는 한 대 서버로부터 응답만 받으면 응답 속도는 빠를 것이다.
  * W, R의 값이 1보다 큰 경우는 일관성 수준은 향상되지만, 응답 속도는 느려질 것이다.
* W, R, N 선정 기준
  * R = 1, W = N: 빠른 읽기 연산에 최적화된 시스템
  * W = 1, R = n: 빠른 쓰기 연산에 최적화된 시스템
  * W + R > N: 강한 일관성이 보장됨 (보통 N = 3, W = R = 2)
  * W + R <= N: 강한 일관성이 보장되지 않음

**일관성 모델**
* 일관성 모델은 키-값 저장소를 설계할 때 고려해야 할 또 하나의 중요한 요소다.
* 일관성 모델은 데이터 일관성의 수주을 결정하는데 종류가 다양하다.
  * 강한 일관성: 모든 읽기 연산은 가장 치근에 갱신된 결과를 반환한다. 다시 말해 클라이언트는 낡은 데이터를 보지 못한다.
  * 약한 일관성: 읽기 연산은 가장 최근에 갱신된 결과를 반환하지 못할 수 있다.
  * 결과적 일관성: 약한 일관성의 한 형태로, 갱신 결과가 결국에는 모든 사본에 반영되는 모델이다.
* 강한 일관성을 달성하는 일반적인 방법은 모든 사본에 현재 쓰기 연산의 결과가 반영될 때까지 해당 데이터에 대한 읽기/쓰기를 금지하는 것이지만 고가용성 시스템에 적합하지 않다.
* 다이나모 또는 카산드라 같은 저장소는 결과적 일관성 모델을 택하고 있는데 쓰기 연산이 병렬적으로 발생하면 시스템에 저장된 값이 깨질 수 있다. 이 문제는 클라이언트가 해결해야 한다.

**비 일관성 해소 기법: 데이터 버저닝**
* 데이터를 다중화하면 가용성은 높아지지만 사본 간 일관성이 깨질 가능성은 높아진다.
* 버저닝과 벡터 시계는 그 문제를 해소하기 위해 등장한 기술이다.
* 버저닝은 데이터를 변경할 때마다 해당 데이터의 새로운 버전을 만드는 것을 의미한다. 따라서 각 버전의 데이터는 변경 불가능하다.
* 벡터 시계는 [서버, 버전]의 순서쌍을 데이터에 매단 것이다. 어떤 버전이 선행 버전인지, 후행 버전인지 아니면 다른 버전과 충돌이 있는지 판별하는데 쓰인다.
* 벡터 시계는 D([S1, v1], [S2, v2]) ...와 같이 표현다고 가정하자.
  * [Si, vi]가 있으면 vi를 증가시킨다.
  * 그렇지 않으면 새 항목 [Si, 1]을 만든다.
* 어떤 버전 X와 Y 사이에 충돌이 있는지 보려면 Y의 벡터 시계 구성요소 가운데 X의 벡터 시계 동일 서버 구성요소보다 작은 값을 갖는 것이 있는지 보면 된다.
  * 충돌 감지 및 해소 로직이 클라이언트에 들어가야 하므로, 클라이언트 구현이 복잡해진다.
  * [서버:버전]의 순서쌍 개수가 굉장히 빨리 늘어난다. 임계치를 설정하고, 임계치보다 길어지면 오래된 순서쌍을 제거하도록 해야한다.
    * 이 경우 버전 간 선후 관계가 정확하게 결정될 수 없어 효율성이 낮아진다고 하지만, AWS 서비스에서는 그런 문제를 발견한 적이 없다고 한다.

**장애 감지**
* 분산 시스템에서는 그저 한 대 서버가 "지금 서버 A가 죽었습니다"라고 한다 해서 바로 서버 A를 장애처리 하지는 않는다.
* 보통 두 대 이상의 서버가 똑같이 서버 A의 장애를 보고해야 해당 서버에 실제로 장애가 발생했다고 간주하게 된다.
* 모든 노드 사이에 멀티캐스팅 채널을 구축하는 것이 서버 장애를 감지하는 가장 손쉬운 방법이다. 하지만 이 방법은 서버가 많을 때는 비효율적이다.
* 가십 프로토콜 같은 분산형 장애 감지 솔루션을 채택하는 편이 보다 효율적이다.
  * 각 노드는 멤버십 목록을 유지한다. 멤버십 목록은 각 멤버 ID와 박동 카운터 쌍의 목록이다.
  * 각 노드는 주기적으로 자신의 박동 카운터를 증가시킨다.
  * 각 노드는 무작위로 선정된 노드들에게 주기적으로 자기 박동 카운터 목록을 보낸다.
  * 박동 카운터 목록을 받은 노드는 멤버십 목록을 최신 값으로 갱신한다.
  * 어떤 멤버의 박동 카운터 값이 지정된 시간 동안 갱신되지 않으면 해당 멤버는 장애 상태인 것으로 간주한다.

**영구 장애 처리**
* 반-엔트로피 프로토콜을 구현하여 사본들을 동기화할 수 있다.
* 사본 간의 일관성이 망가진 상태를 탐지하고 전송 데이터의 양을 줄이기 위해서 머클 트리를 사용한다.
  * 머클 트리: 해시 트리라고도 불리는 머클 트리는 각 노드에 그 자식 노드들의 레이블로부터 계산된 해시 값을 레이블로 붙여두는 트리다.
  * 해시 트리를 사용하면 대규모 자료 구조의 내용을 효과적이면서도 보안상 안전한 방법으로 검증할 수 있다.
* 처리 단계
  * 키 공간을 버킷의 개수를 정해 나눈다.
  * 버킷에 포함된 각각의 키에 균등 분포 해시 함수를 적용해 해시 값을 계산한다.
  * 버킷별로 해시값을 계산한 후, 해당 캐시 값을 레이블로 갖는 노드를 만든다.
  * 자식 노드의 레이블로부터 새로운 해시 값을 계산하여, 이진 트리를 상향식으로 구성해 나간다.
* 루트 노드의 해시 값이 일치한다면 두 서버는 같은 데이터를 갖는 것이다.
* 값이 다른 경우 왼쪽 자식 노드의 해시 값을 비교하고, 그 다음으로 오른쪽 자식 노드의 해시 값을 비교한다.
* 이렇게 아래쪽으로 탐색해 나가다 보면 다른 데이터를 갖는 버킷을 찾을 수 있으므로, 그 버킷들만 동기화하면 된다